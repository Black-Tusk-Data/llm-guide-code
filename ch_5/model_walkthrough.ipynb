{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fff1b1b-f0b5-4c85-a18b-050338eaaa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'AutoModelForCausalLM' is just an interface into the language model.\n",
    "# 'CausalLM' refers to left-to-right language modeling, or next-token-prediction.\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01470bda-0231-497e-acd9-451814b478dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce198bea6b2480e8653ad8b13da5795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "causal_lm_model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "model = causal_lm_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241e997d-35e7-4bb8-a0d2-8b47622b7b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phi3Model(\n",
       "  (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
       "  (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0-31): 32 x Phi3DecoderLayer(\n",
       "      (self_attn): Phi3SdpaAttention(\n",
       "        (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "        (qkv_proj): Linear(in_features=3072, out_features=9216, bias=False)\n",
       "        (rotary_emb): Phi3RotaryEmbedding()\n",
       "      )\n",
       "      (mlp): Phi3MLP(\n",
       "        (gate_up_proj): Linear(in_features=3072, out_features=16384, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "        (activation_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "      (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (post_attention_layernorm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       "    )\n",
       "  )\n",
       "  (norm): Phi3RMSNorm((3072,), eps=1e-05)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4edcecf-aea0-4dbc-a360-54ac2f8f8084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3072, out_features=32064, bias=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal_lm_model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a535b1-a908-405d-b52c-1cff20033ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32064, 3072, padding_idx=32000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "674f2260-41b1-4339-8f52-d3881e544937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11a9c337-8356-487d-909b-71b829441c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4703a367-ef3a-4785-aaac-2dece5676add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_prompt(*, system: str, user: str) -> str:\n",
    "    return \"\\n\".join([\n",
    "        \"<|system|>\",\n",
    "        f\"{system}<|end|>\",\n",
    "        \"<|user|>\",\n",
    "        f\"{user}<|end|>\",\n",
    "        \"<|assistant|>\",\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91038860-f5dd-46a0-b3c2-473a96e40733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = phi_prompt(\n",
    "    system=\"\",\n",
    "    user=\"A journey of a thousand miles begins with a single \",\n",
    ")\n",
    "inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "input_batch = inputs[\"input_ids\"]\n",
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "951ea13f-8dd1-4ea8-95d8-bef6ad172838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 3072])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_embeds = model.embed_tokens(input_batch)\n",
    "inputs_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09d3c239-6741-44cc-8d0a-f1319708421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = inputs_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c98dfc2-54ad-406b-9210-b818e08a4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids = torch.tensor(range(0, input_batch.shape[1])).unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9d49ea4-c969-4b1d-8e7c-74ab8abefe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0\n",
      "layer 1\n",
      "layer 2\n",
      "layer 3\n",
      "layer 4\n",
      "layer 5\n",
      "layer 6\n",
      "layer 7\n",
      "layer 8\n",
      "layer 9\n",
      "layer 10\n",
      "layer 11\n",
      "layer 12\n",
      "layer 13\n",
      "layer 14\n",
      "layer 15\n",
      "layer 16\n",
      "layer 17\n",
      "layer 18\n",
      "layer 19\n",
      "layer 20\n",
      "layer 21\n",
      "layer 22\n",
      "layer 23\n",
      "layer 24\n",
      "layer 25\n",
      "layer 26\n",
      "layer 27\n",
      "layer 28\n",
      "layer 29\n",
      "layer 30\n",
      "layer 31\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(\"layer\", i)\n",
    "    residual = hidden_states\n",
    "    hidden_states = layer.input_layernorm(hidden_states)\n",
    "    attn_outputs, _self_attn_weights, _present_key_value = layer.self_attn(\n",
    "        hidden_states=hidden_states,\n",
    "        position_ids=position_ids,\n",
    "        output_attentions=False,\n",
    "        use_cache=False,\n",
    "    )\n",
    "    hidden_states = residual + attn_outputs\n",
    "    residual = hidden_states\n",
    "    hidden_states = layer.post_attention_layernorm(hidden_states)\n",
    "    hidden_states = layer.mlp(hidden_states)\n",
    "    hidden_states = residual + layer.resid_mlp_dropout(hidden_states)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "280fa00c-0c3d-42bc-89f6-e1762182038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_hidden_state = model.norm(hidden_states)\n",
    "last_token_hidden_state = normed_hidden_state[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02cb669f-03cc-44a6-bec1-705af161a70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_logits = causal_lm_model.lm_head(last_token_hidden_state)\n",
    "logits = batch_logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10aab70c-ac38-4895-8d94-8f813f536094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'step'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = torch.argmax(logits)\n",
    "tokenizer.decode(token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
