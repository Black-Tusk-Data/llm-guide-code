{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a19a702b-edfd-4c3c-87e3-44a8046bffe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lm-format-enforcer\n",
      "  Downloading lm_format_enforcer-0.10.9-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 KB\u001b[0m \u001b[31m503.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers==4.41.2\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: accelerate in ./venv/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in ./venv/lib/python3.10/site-packages (from transformers==4.41.2) (0.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from transformers==4.41.2) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from transformers==4.41.2) (2.1.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers==4.41.2) (4.66.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers==4.41.2) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.10/site-packages (from transformers==4.41.2) (0.4.5)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers==4.41.2) (2.32.3)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers==4.41.2) (3.16.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from transformers==4.41.2) (24.1)\n",
      "Collecting interegular>=0.3.2\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Collecting pydantic>=1.10.8\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in ./venv/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (4.12.2)\n",
      "Collecting pydantic-core==2.23.4\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (3.4.1)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.41.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.41.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.41.2) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->transformers==4.41.2) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Installing collected packages: pydantic-core, interegular, annotated-types, pydantic, tokenizers, lm-format-enforcer, transformers, bitsandbytes\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.1\n",
      "    Uninstalling tokenizers-0.20.1:\n",
      "      Successfully uninstalled tokenizers-0.20.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.45.2\n",
      "    Uninstalling transformers-4.45.2:\n",
      "      Successfully uninstalled transformers-4.45.2\n",
      "Successfully installed annotated-types-0.7.0 bitsandbytes-0.44.1 interegular-0.3.3 lm-format-enforcer-0.10.9 pydantic-2.9.2 pydantic-core-2.23.4 tokenizers-0.19.1 transformers-4.41.2\n"
     ]
    }
   ],
   "source": [
    "! python -m pip install lm-format-enforcer transformers==4.41.2 bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1064043-3ddf-41f8-b2ab-08e56ff8426a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pydantic import BaseModel\n",
    "from lmformatenforcer import JsonSchemaParser\n",
    "from lmformatenforcer.integrations.transformers import build_transformers_prefix_allowed_tokens_fn\n",
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498bd4c1-cee7-4146-b5e3-261e31bf750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/Phi-3-mini-128k-instruct\"\n",
    "#model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "device = \"cuda\"\n",
    "#device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "414f92f9-13d2-46a6-8d2c-d8dee9a4c4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    #bnb_4bit_block_size=64,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    #llm_int8_enable_fp32_cpu_offload=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71c28a4c-9726-499c-92ae-1eb2d7b73008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Downloading shards: 100%|██████████| 2/2 [02:33<00:00, 76.86s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.51s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    quantization_config=quantization_config, \n",
    "    trust_remote_code=True, \n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0fec47-453b-416e-90b8-0649ae262c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id, \n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a017990-85ca-41cc-a77d-52458c5a0268",
   "metadata": {},
   "source": [
    "## Manual enforcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5bc9c807-350f-4b59-9027-3ca10a6f0ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_token_ids = torch.tensor([\n",
    "    token_id for word, token_id in tokenizer.vocab.items() \n",
    "    if (word.upper() == word and \":\" not in word)\n",
    "    or token_id in tokenizer.all_special_tokens\n",
    "]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d84a22b8-72c4-49ca-aa1e-b8cbd3455692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_prompt(*, system: str, user: str) -> str: \n",
    "    return \"\\n\".join([\n",
    "        \"<|system|>\", \n",
    "        f\"{system}<|end|>\", \n",
    "        \"<|user|>\", \n",
    "        f\"{user}<|end|>\", \n",
    "        \"<|assistant|>\",\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "92e71169-f66e-463d-bf8b-7ebe70020894",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = phi_prompt(\n",
    "    system=\"You are a helpful history expert\",\n",
    "    user=\"Who was the first man on the moon?\",\n",
    ")\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "553c2e5b-7d3c-4f5e-87a2-1a3c1209ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(input_ids) -> bool:\n",
    "    logits = model(input_ids).logits\n",
    "    prediction_logits = logits[:, -1, :].squeeze(dim=0)\n",
    "    # restrict to the allowed tokens!\n",
    "    allowed_predictions = prediction_logits[allowed_token_ids]\n",
    "    token_idx = torch.argmax(allowed_predictions).item()\n",
    "    next_token_id = allowed_token_ids[token_idx]\n",
    "    # append the next_token\n",
    "    return torch.cat((\n",
    "    input_ids,\n",
    "        next_token_id.unsqueeze(0).unsqueeze(0),\n",
    "    ), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "14cb9ad3-3f58-4089-9ff0-39ecd8f731a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "ASTR\n",
      "ASTRON\n",
      "ASTRONAUT\n",
      "ASTRONAUTS\n",
      "ASTRONAUTS NE\n",
      "ASTRONAUTS NEIL\n",
      "ASTRONAUTS NEIL AR\n",
      "ASTRONAUTS NEIL ARM\n",
      "ASTRONAUTS NEIL ARMSTR\n",
      "ASTRONAUTS NEIL ARMSTRONG\n",
      "ASTRONAUTS NEIL ARMSTRONG AND\n",
      "ASTRONAUTS NEIL ARMSTRONG AND B\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL D\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL DAV\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL DAVIES\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL DAVIES W\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL DAVIES WERE\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL DAVIES WERE THE\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL DAVIES WERE THE F\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL DAVIES WERE THE FIR\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL DAVIES WERE THE FIRST\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL DAVIES WERE THE FIRST M\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL DAVIES WERE THE FIRST MEN\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL DAVIES WERE THE FIRST MEN TO\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL DAVIES WERE THE FIRST MEN TO S\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL DAVIES WERE THE FIRST MEN TO STE\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL DAVIES WERE THE FIRST MEN TO STEP\n",
      "ASTRONAUTS NEIL ARMSTRONG AND BILL DAVIES WERE THE FIRST MEN TO STEP ON\n"
     ]
    }
   ],
   "source": [
    "seq = input_ids\n",
    "# we'll arbitrarily predict the next 30 tokens\n",
    "for i in range(30):\n",
    "    seq = step(seq)\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            seq[0][input_ids.shape[-1]:].squeeze()\n",
    "        )\n",
    "    )\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6dbb77-19b8-4871-9070-aaa351f4f314",
   "metadata": {},
   "source": [
    "## Using 'lm-format-enforcer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "26d5bbf0-3b0c-4000-8ea2-97da944d358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryShape(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    birthplace: str\n",
    "    profession: str\n",
    "    nicknames: list[str]\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "022c0c5f-5b62-4b61-b68b-eb68ce85f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PAGE_LENGTH = 40000\n",
    "def get_plaintext_wikipedia_page(title):\n",
    "    import requests\n",
    "    url = f\"https://en.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"prop\": \"extracts\",\n",
    "        \"explaintext\": True,\n",
    "        \"titles\": title,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    page = next(iter(data['query']['pages'].values()))\n",
    "    return page['extract'][:MAX_PAGE_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cb15e526-3e73-4f55-b631-e239911cfd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael Jeffrey Jordan (born February 17, 1963), also known by his initials MJ, is an American businessman and former professional basketball player. He played 15 seasons in the National Basketball Association (NBA) between 1984 and 2003, winning six ...\n"
     ]
    }
   ],
   "source": [
    "plaintext_contents = get_plaintext_wikipedia_page(\"Michael_Jordan\")\n",
    "print(plaintext_contents[:250], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "66c23ede-ebe9-4891-93ac-8f719e1f7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline('text-generation', model=model, tokenizer=tokenizer, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1496ffef-454e-42ba-a82f-9be3a4ed92b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonSchemaParser(SummaryShape.schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0a89e520-2d3a-4b45-9efa-36187533b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_function = build_transformers_prefix_allowed_tokens_fn(pipe.tokenizer, parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "19e24b5d-cd6e-456d-8d07-fa2d00d9aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_structured_output(prompt: str):\n",
    "    with torch.no_grad():\n",
    "        output_dict = pipe(\n",
    "            prompt,\n",
    "            max_new_tokens=250,\n",
    "            prefix_allowed_tokens_fn=prefix_function\n",
    "        )\n",
    "        return json.loads(output_dict[0]['generated_text'][-1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ea7e42fb-6664-4f6f-9f49-9e888e9cb043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Michael Jordan',\n",
       " 'nicknames': ['Air Jordan', 'His Airness'],\n",
       " 'profession': 'Basketball Player',\n",
       " 'birthplace': 'Brooklyn, New York City, New York',\n",
       " 'age': 61}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_structured_output([\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that responds in JSON\"},\n",
    "    {\"role\": \"user\", \"content\": \"\\n\".join([\n",
    "        \"Sumamrize (in JSON format) the following information\",\n",
    "        plaintext_contents,    \n",
    "    ])}\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
