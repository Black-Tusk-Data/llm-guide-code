{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "570b7cd1-60e6-4cf6-af9b-72f86c996c3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: lm-format-enforcer in ./venv/lib/python3.10/site-packages (0.10.9)\n",
      "Requirement already satisfied: bitsandbytes in ./venv/lib/python3.10/site-packages (0.44.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./venv/lib/python3.10/site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: pyyaml in ./venv/lib/python3.10/site-packages (from lm-format-enforcer) (6.0.2)\n",
      "Requirement already satisfied: interegular>=0.3.2 in ./venv/lib/python3.10/site-packages (from lm-format-enforcer) (0.3.3)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in ./venv/lib/python3.10/site-packages (from lm-format-enforcer) (2.9.2)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from lm-format-enforcer) (24.1)\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.10/site-packages (from pydantic>=1.10.8->lm-format-enforcer) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.10/site-packages (from pydantic>=1.10.8->lm-format-enforcer) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./venv/lib/python3.10/site-packages (from pydantic>=1.10.8->lm-format-enforcer) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (3.16.1)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (3.4.1)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (2.20.5)\n",
      "Requirement already satisfied: triton==3.0.0 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (3.0.0)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! python -m pip install pandas lm-format-enforcer bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcae4d1a-9dc2-40fc-8368-0aa13046ffa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lmformatenforcer.integrations.transformers import build_transformers_prefix_allowed_tokens_fn\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig,\n",
    "    GenerationConfig,\n",
    ")\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4842977-5dfd-452f-bd62-9a6f54782d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmformatenforcer import RegexParser\n",
    "# we expect either a '1' or a '2' as a response\n",
    "parser = RegexParser(\"[12]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781c6f1c-791d-4c85-8fd4-7d8902f9c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "#model_id = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "#model_id = \"google/gemma-2-2b-it\"\n",
    "model_id = \"microsoft/Phi-3-mini-128k-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca8bb5d-c95e-4f85-b538-e182582f1e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 2/2 [00:44<00:00, 22.43s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.01s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "# we'll quantize pretty aggressively, for improved inference speed\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    llm_int8_enable_fp32_cpu_offload=True,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    quantization_config=quantization_config,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39aaf316-7144-4a4c-9c09-fe836cbeaec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_function = build_transformers_prefix_allowed_tokens_fn(tokenizer, parser)\n",
    "def classify(input_s: str):\n",
    "    input_ids = tokenizer(input_s, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **input_ids,\n",
    "        generation_config=GenerationConfig(max_new_tokens=1),\n",
    "        prefix_allowed_tokens_fn=prefix_function,\n",
    "    )\n",
    "    output_s = tokenizer.decode(outputs[0])\n",
    "    return int(output_s[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "925966b2-0a26-42d1-9649-ea70426f8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_prompt_llama(contents: str) -> str:\n",
    "    return \"\\n\".join([\n",
    "        \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\",\n",
    "        \"\".join([\n",
    "            \"You are a helpful spam email detector.\",\n",
    "            \"Given an email, respond with the number '1' if the email is certainly spam, otherwise the number '2'.\",\n",
    "            \"<|eot_id|><|start_header_id|>user<|end_header_id|>\",\n",
    "        ]),\n",
    "        \"\".join([\n",
    "            \"EMAIL:\",\n",
    "            contents,\n",
    "            \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\",\n",
    "        ]),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53cd3c32-1714-40fe-8430-43e939fa7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_prompt_gemma(contents: str) -> str:\n",
    "    return \"\\n\".join([\n",
    "        \"<bos><start_of_turn>user\",\n",
    "        \" \".join([\n",
    "            \"You are a helpful spam email detector.\",\n",
    "            \"Given an email, respond with the number '1' if the email is likely spam, otherwise the number '2'.\",\n",
    "            f\"EMAIL: {contents}<end_of_turn>\",            \n",
    "        ]),\n",
    "        \"<start_of_turn>model\",\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3abedfd-ac3c-4781-a831-72dd46721c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_prompt_phi(contents: str) -> str:\n",
    "    return \"\\n\".join([\n",
    "        \"<|system|>\",\n",
    "        \"You are a helpful spam email detector.  Given an email, respond with the number '1' if it is trying to sell something, otherwise the number '2'.<|end|>\",\n",
    "        \"<|user|>\",\n",
    "        f\"Classify the following email: {contents}<|end|>\",\n",
    "        \"<|assistant|>\",\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc29e900-8fb1-4138-80ea-a6dcf9628ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>bootstrap_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Subject: great nnews  hello , welcome to medzo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Subject: here ' s a hot play in motion  homela...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Subject: save your money buy getting this thin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Subject: undeliverable : home based business f...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Subject: save your money buy getting this thin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>Subject: hello guys ,  i ' m \" bugging you \" f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>Subject: sacramento weather station  fyi  - - ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>Subject: from the enron india newsdesk - jan 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>Subject: re : powerisk 2001 - your invitation ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>Subject: re : resco database and customer capt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>Subject: ben zhang  any suggestions ?  - g  - ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>Subject: manoj gupta - interview schedule  att...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>Subject: re : hello from vince kaminski at enr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>Subject: candlestick charts  fyi fallout  - - ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>Subject: faculty information sheet  mr . kamin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam  bootstrap_spam\n",
       "0     Subject: naturally irresistible your corporate...     1               1\n",
       "1     Subject: the stock trading gunslinger  fanny i...     1               0\n",
       "2     Subject: unbelievable new homes made easy  im ...     1               1\n",
       "3     Subject: 4 color printing special  request add...     1               1\n",
       "4     Subject: do not have money , get software cds ...     1               1\n",
       "5     Subject: great nnews  hello , welcome to medzo...     1               1\n",
       "6     Subject: here ' s a hot play in motion  homela...     1               0\n",
       "7     Subject: save your money buy getting this thin...     1               1\n",
       "8     Subject: undeliverable : home based business f...     1               1\n",
       "9     Subject: save your money buy getting this thin...     1               1\n",
       "1368  Subject: hello guys ,  i ' m \" bugging you \" f...     0               0\n",
       "1369  Subject: sacramento weather station  fyi  - - ...     0               0\n",
       "1370  Subject: from the enron india newsdesk - jan 1...     0               0\n",
       "1371  Subject: re : powerisk 2001 - your invitation ...     0               0\n",
       "1372  Subject: re : resco database and customer capt...     0               0\n",
       "1373  Subject: ben zhang  any suggestions ?  - g  - ...     0               0\n",
       "1374  Subject: manoj gupta - interview schedule  att...     0               0\n",
       "1375  Subject: re : hello from vince kaminski at enr...     0               0\n",
       "1376  Subject: candlestick charts  fyi fallout  - - ...     0               0\n",
       "1377  Subject: faculty information sheet  mr . kamin...     0               0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT_FORMATTERS = {\n",
    "    \"google/gemma-2-2b-it\": fmt_prompt_gemma,\n",
    "    \"microsoft/Phi-3-mini-128k-instruct\": fmt_prompt_phi,\n",
    "    \"meta-llama/Meta-Llama-3.1-8B-Instruct\": fmt_prompt_llama,\n",
    "}\n",
    "df = pd.read_csv(\"./emails.csv\")\n",
    "manual_init = pd.concat((\n",
    "    df[df[\"spam\"] == 1].iloc[:10],\n",
    "    df[df[\"spam\"] == 0].iloc[:10],\n",
    "))\n",
    "prompt_formatter = PROMPT_FORMATTERS[model_id]\n",
    "manual_init[\"bootstrap_spam\"] = manual_init[\"text\"].apply(\n",
    "    lambda text: classify(prompt_formatter(text)) %2\n",
    ")\n",
    "manual_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58e36aa9-db44-4cc7-9ea9-02dd33cdf943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manual_init[manual_init[\"spam\"] == manual_init[\"bootstrap_spam\"]]) / len(manual_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bba3276-6291-42a9-a117-adb2d26c270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = {\n",
    "    \"gemma\": 0.6,\n",
    "    \"phi\": 0.9,\n",
    "    \"llama\": 0.65,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16f5176-a6fe-4f1e-b625-a132cc0b4149",
   "metadata": {},
   "source": [
    "Now, we'll create an initial bootstrapped labeling of the entire dataset using this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d78f70d3-3d01-41c2-9f57-11723a9ad1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5728/5728 [13:27<00:00,  6.80it/s]"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./emails.csv\")\n",
    "bootstrap_spam = []\n",
    "progress_bar = tqdm(range(len(df)))\n",
    "for i, row in df.iterrows():\n",
    "    bootstrap_spam.append(\n",
    "        classify(prompt_formatter(row[\"text\"])) %2\n",
    "    )\n",
    "    progress_bar.update(1)\n",
    "    pass\n",
    "df[\"bootstrap_spam\"] = bootstrap_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a22e7142-7fa7-4564-ba67-524c0b1418f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"emails_bootstrapped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dd86310-ac7c-4f30-9671-72f1c48dac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat((\n",
    "    df[df[\"spam\"] == 1].iloc[:50],\n",
    "    df[df[\"spam\"] == 0].iloc[:50],\n",
    ")).to_csv(\"emails_bootstrapped_mixed_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5010d140-656c-408a-9b73-2c97165ddc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8170391061452514"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"spam\"] == df[\"bootstrap_spam\"]]) / len(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
